{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "PREPROCESSING\n"
      ],
      "metadata": {
        "id": "-CnuHDRK-Xnq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLzBvDqV9eR-"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "## Cleaning and Tokenization\n",
        "def process_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
        "    text = text.lower().strip()\n",
        "    tokens = word_tokenize(text)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "#Convert Text to Numerical\n",
        "def vector_text(train_text, test_text):\n",
        "    vectorizer = TfidfVectorizer(max_features= 5000)\n",
        "    X_train = vectorizer.fit_transform(train_text)\n",
        "    X_test = vectorizer.fit_transform(test_text)\n",
        "    return X_train, X_test, vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN\n"
      ],
      "metadata": {
        "id": "obhCR3f6-V0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from preprocess import process_text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#Load Dataset\n",
        "file = 'C:/Users/kelly/PycharmProjects/PythonProject1/data/Sentences_AllAgree.txt'\n",
        "sentences = [ ]\n",
        "labels = [ ]\n",
        "\n",
        "with open(file, 'r', encoding='ISO-8859-1') as file:\n",
        "    for line in file:\n",
        "        parts = line.rsplit('@, 1')\n",
        "        if len(parts)== 2:\n",
        "            sentences.append(parts[0].strip())\n",
        "            labels.append(parts[1].strip())\n",
        "\n",
        "\n",
        "#Convert Labels into Numeric\n",
        "label_mapping = {'positive' : 1,\n",
        "                 'negative':-1,\n",
        "                 'neutral': 0}\n",
        "y =[label_mapping[label] for  label in labels]\n",
        "\n",
        "#Preprocess Text\n",
        "sentences = [process_text(sentence) for sentence in sentences]\n",
        "\n",
        "#Spliting the data into train and test\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(sentences, y, test_size=0.2, random_state=42)\n",
        "\n",
        "from collections import Counter\n",
        "print('Label Information: ', Counter(y_train))\n",
        "\n",
        "#Convert text to numerical features\n",
        "vectorizer = TfidfVectorizer(max_features=10000)\n",
        "\n",
        "#Words embedding\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "x_train_vec = embed_model.encode(x_train)\n",
        "x_test_vec = embed_model.encode(x_test)\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "x_train_imb, y_train_imb = smote.fit_resample(x_train_vec, y_train)\n",
        "\n",
        "from collections import Counter\n",
        "print('Label Information: ', Counter(y_train_imb))\n",
        "\n",
        "#Train model using SVC\n",
        "model_svc = SVC(kernel='linear')\n",
        "model_svc.fit(x_train_imb,y_train_imb)\n",
        "\n",
        "#Evaluation\n",
        "y_pred_svc = model_svc.predict(x_test_vec)\n",
        "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
        "print(f'SVC Model Accuracy: {accuracy_svc}')\n",
        "\n",
        "with open('C:/Users/kelly/PycharmProjects/PythonProject1/sentiment.pkl', 'wb') as f:\n",
        "    pickle.dump(model_svc, f)\n",
        "\n",
        "with open('C:/Users/kelly/PycharmProjects/PythonProject1/transformer.pkl', 'wb') as f:\n",
        "    pickle.dump(embed_model, f)"
      ],
      "metadata": {
        "id": "cFg5f7bL-TWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREDICT"
      ],
      "metadata": {
        "id": "JOXLkevS-cnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from preprocess import process_text\n",
        "\n",
        "#Load the Models\n",
        "with open('C:/Users/Admin/Desktop/Financial Analysis/sentiment.pkl', 'rb') as f:\n",
        "    model_svc = pickle.load(f)\n",
        "\n",
        "with open('C:/Users/Admin/Desktop/Financial Analysis/transformer.pkl', 'rb') as f:\n",
        "     embed_model = pickle.load(f)\n",
        "\n",
        "\n",
        "#To predict the test\n",
        "\n",
        "def predict(text):\n",
        "    processed_text = process_text(text)\n",
        "    vectorized_text = embed_model.encode([processed_text])\n",
        "    prediction = model_svc.predict(vectorized_text)[0]\n",
        "    sentiment_map = {'positive': 1,\n",
        "                 'negative': 1,\n",
        "                 'neutral': 0}\n",
        "    return sentiment_map[prediction]\n",
        "\n",
        "\n",
        "#Test the function\n",
        "if __name__ == '__main__':\n",
        "    user_text = input('Enter the sentence: ')\n",
        "    print('Sentiments:', predict(user_input))\n",
        "\n"
      ],
      "metadata": {
        "id": "zRRKK5-J-b4A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}